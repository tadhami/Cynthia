{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL 'None': No scheme supplied. Perhaps you meant http://None?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000000?line=58'>59</a>\u001b[0m         \u001b[39mlist\u001b[39m[i] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mfilter\u001b[39m(\u001b[39mstr\u001b[39m\u001b[39m.\u001b[39misalnum, \u001b[39mlist\u001b[39m[i]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000000?line=59'>60</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m \n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000000?line=61'>62</a>\u001b[0m my_soup \u001b[39m=\u001b[39m get_pogo_soup(link)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000000?line=63'>64</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_pogo_site_info\u001b[39m(soup, info_to_get, timeframe):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000000?line=64'>65</a>\u001b[0m     res \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32m/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb Cell 1\u001b[0m in \u001b[0;36mget_pogo_soup\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000000?line=35'>36</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_pogo_soup\u001b[39m(url):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000000?line=36'>37</a>\u001b[0m     page \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000000?line=37'>38</a>\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(page\u001b[39m.\u001b[39mcontent, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000000?line=38'>39</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m soup\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/requests/api.py:75\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     65\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m'\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m'\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/requests/sessions.py:515\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[39m# Create the Request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m req \u001b[39m=\u001b[39m Request(\n\u001b[1;32m    504\u001b[0m     method\u001b[39m=\u001b[39mmethod\u001b[39m.\u001b[39mupper(),\n\u001b[1;32m    505\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m     hooks\u001b[39m=\u001b[39mhooks,\n\u001b[1;32m    514\u001b[0m )\n\u001b[0;32m--> 515\u001b[0m prep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_request(req)\n\u001b[1;32m    517\u001b[0m proxies \u001b[39m=\u001b[39m proxies \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    519\u001b[0m settings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmerge_environment_settings(\n\u001b[1;32m    520\u001b[0m     prep\u001b[39m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[1;32m    521\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/requests/sessions.py:443\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    440\u001b[0m     auth \u001b[39m=\u001b[39m get_netrc_auth(request\u001b[39m.\u001b[39murl)\n\u001b[1;32m    442\u001b[0m p \u001b[39m=\u001b[39m PreparedRequest()\n\u001b[0;32m--> 443\u001b[0m p\u001b[39m.\u001b[39;49mprepare(\n\u001b[1;32m    444\u001b[0m     method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod\u001b[39m.\u001b[39;49mupper(),\n\u001b[1;32m    445\u001b[0m     url\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49murl,\n\u001b[1;32m    446\u001b[0m     files\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mfiles,\n\u001b[1;32m    447\u001b[0m     data\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mdata,\n\u001b[1;32m    448\u001b[0m     json\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mjson,\n\u001b[1;32m    449\u001b[0m     headers\u001b[39m=\u001b[39;49mmerge_setting(request\u001b[39m.\u001b[39;49mheaders, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders, dict_class\u001b[39m=\u001b[39;49mCaseInsensitiveDict),\n\u001b[1;32m    450\u001b[0m     params\u001b[39m=\u001b[39;49mmerge_setting(request\u001b[39m.\u001b[39;49mparams, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams),\n\u001b[1;32m    451\u001b[0m     auth\u001b[39m=\u001b[39;49mmerge_setting(auth, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauth),\n\u001b[1;32m    452\u001b[0m     cookies\u001b[39m=\u001b[39;49mmerged_cookies,\n\u001b[1;32m    453\u001b[0m     hooks\u001b[39m=\u001b[39;49mmerge_hooks(request\u001b[39m.\u001b[39;49mhooks, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhooks),\n\u001b[1;32m    454\u001b[0m )\n\u001b[1;32m    455\u001b[0m \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/requests/models.py:318\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_method(method)\n\u001b[0;32m--> 318\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_url(url, params)\n\u001b[1;32m    319\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_headers(headers)\n\u001b[1;32m    320\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_cookies(cookies)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/requests/models.py:392\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    389\u001b[0m     error \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mInvalid URL \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m: No scheme supplied. Perhaps you meant http://\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    390\u001b[0m     error \u001b[39m=\u001b[39m error\u001b[39m.\u001b[39mformat(to_native_string(url, \u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m--> 392\u001b[0m     \u001b[39mraise\u001b[39;00m MissingSchema(error)\n\u001b[1;32m    394\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m host:\n\u001b[1;32m    395\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidURL(\u001b[39m\"\u001b[39m\u001b[39mInvalid URL \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m: No host supplied\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m url)\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL 'None': No scheme supplied. Perhaps you meant http://None?"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import datetime\n",
    "import pandas as pd \n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "def get_pogo_content_update_link(month_to_check):\n",
    "    ''' \n",
    "    month_to_check can be current or next month \n",
    "    '''\n",
    "    pogo_news_url = 'https://pokemongolive.com/en/news/'\n",
    "    pogo_general_url = 'https://pokemongolive.com'\n",
    "\n",
    "    news_page = requests.get(pogo_news_url)\n",
    "    news_soup = BeautifulSoup(news_page.content, \"html.parser\")\n",
    "    current_month_num = now.month \n",
    "    current_month = now.strftime(\"%B\")\n",
    "    next_month = (now + relativedelta(months=1)).strftime('%B')\n",
    "    blogpost_links = news_soup.findAll('a', attrs = {'class':'blogList__post'})\n",
    "\n",
    "    if month_to_check == 'current':\n",
    "        for item in blogpost_links:\n",
    "            if 'content-update' in item['href'] and current_month.lower() in item['href']:\n",
    "                return pogo_general_url + item['href']\n",
    "    if month_to_check == 'next':\n",
    "        for item in blogpost_links:\n",
    "            if 'content-update' in item['href'] and next_month.lower() in item['href']:\n",
    "                return pogo_general_url + item['href']\n",
    "\n",
    "link = get_pogo_content_update_link('next')\n",
    "print(link)\n",
    "\n",
    "def get_pogo_soup(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    return soup \n",
    "\n",
    "def build_pogo_df(result, names_list, dates_list):\n",
    "    for i in range(len(names_list)):\n",
    "        row = []\n",
    "        name = names_list[i]\n",
    "        row.append(name)\n",
    "        date = dates_list[i]\n",
    "        row.append(date)\n",
    "        result.append(row)\n",
    "    return result\n",
    "\n",
    "def pogo_general_text_strip(list):\n",
    "    for i in range(len(list)):\n",
    "        list[i] = list[i].text.strip()\n",
    "    return list \n",
    "\n",
    "def pogo_names_text_strip(list):\n",
    "    for i in range(len(list)):\n",
    "        list[i] = list[i].text.strip()\n",
    "        list[i] = ''.join(filter(str.isalnum, list[i]))\n",
    "    return list \n",
    "\n",
    "my_soup = get_pogo_soup(link)\n",
    "\n",
    "def get_pogo_site_info(soup, info_to_get, timeframe):\n",
    "    res = []\n",
    "    if timeframe == 'next':\n",
    "        month = (now + relativedelta(months=1)).strftime('%B')\n",
    "    elif timeframe == 'current':\n",
    "        month = now.strftime(\"%B\")\n",
    "    \n",
    "    five_star_raid_table = soup.find(text = 'Five-Star Raids').findPrevious('div', attrs = {'class':'ContainerBlock'}).find('div', attrs = {'class':\"MarkdownBlock__blocks\"})\n",
    "    five_star_names = five_star_raid_table.findAll('div', attrs = {'class':\"PokemonImageGridBlock__grid__pokemon__caption\"})\n",
    "    five_star_names = pogo_names_text_strip(five_star_names)\n",
    "    five_star_raid_dates = soup.find(text = 'Five-Star Raids').findPrevious('div', attrs = {'class':'ContainerBlock'}).findAll('strong')\n",
    "\n",
    "    # Handle if multiple pokemon per date\n",
    "    for i in range(len(five_star_raid_dates)):\n",
    "        five_star_pokemon_on_site = five_star_raid_dates[i].findNext('div',attrs={'class':\"block block--PokemonImageGridBlock\"}).findAll('div', attrs={'class':'PokemonImageGridBlock__grid__pokemon__caption'})\n",
    "        date_duplicate_count = len(five_star_pokemon_on_site)\n",
    "        # if multiple pokemon for a date, duplicate that date entry in the list\n",
    "        if (date_duplicate_count > 1):\n",
    "            five_star_raid_dates.insert(i, five_star_raid_dates[i])\n",
    "        five_star_raid_dates[i] = five_star_raid_dates[i].text.strip()\n",
    "\n",
    "    res = build_pogo_df(res, five_star_names, five_star_raid_dates)\n",
    "    df = pd.DataFrame(res, columns=[\"Name\" ,\"Dates\"])\n",
    "\n",
    "    df_prime = df.to_string(index = False, justify='center')\n",
    "\n",
    "    mega_raid_table = soup.find(text = 'Mega Raids').findPrevious('div', attrs = {'class':'ContainerBlock'}).find('div', attrs = {'class':\"MarkdownBlock__blocks\"})\n",
    "    mega_pokemon_on_site = mega_raid_table.findAll('div', attrs = {'class':\"PokemonImageGridBlock__grid__pokemon__caption\"})\n",
    "    mega_pokemon_on_site = pogo_names_text_strip(mega_pokemon_on_site)    \n",
    "    mega_raid_dates = soup.find(text = 'Mega Raids').findPrevious('div', attrs = {'class':'ContainerBlock'}).findAll('strong')\n",
    "    \n",
    "    # Handle if multiple pokemon per date\n",
    "    for i in range(len(mega_raid_dates)):\n",
    "        mega_pokemon_on_site = mega_raid_dates[i].findNext('div',attrs={'class':\"block block--PokemonImageGridBlock\"}).findAll('div', attrs={'class':'PokemonImageGridBlock__grid__pokemon__caption'})\n",
    "        date_duplicate_count = len(mega_pokemon_on_site)\n",
    "        # if multiple pokemon for a date, duplicate that date entry in the list\n",
    "        if (date_duplicate_count > 1):\n",
    "            mega_raid_dates.insert(i, mega_raid_dates[i])\n",
    "        mega_raid_dates[i] = mega_raid_dates[i].text.strip()\n",
    "\n",
    "    raid_hour_table = soup.find(text = 'Raid Hours').findPrevious('div', attrs = {'class':'ContainerBlock'}).find('div', attrs = {'class':\"MarkdownBlock__blocks\"})\n",
    "    raid_hours_on_site = raid_hour_table.findAll('div', attrs = {'class':\"PokemonImageGridBlock__grid__pokemon__caption\"})\n",
    "    raid_hours_on_site = pogo_general_text_strip(raid_hours_on_site)\n",
    "\n",
    "    # research_breakthrough_table = soup.find(text = (now + relativedelta(months=1)).strftime('%B') + ' Research Breakthrough encounters').findPrevious('div', attrs = {'class':'ContainerBlock'}).find('div', attrs = {'class':\"MarkdownBlock__blocks\"})\n",
    "    research_breakthrough_name = soup.find(text = month + ' Research Breakthrough encounters').findPrevious('div', attrs = {'class':'ContainerBlock'}).find('div', attrs = {'class':\"PokemonImageGridBlock__grid__pokemon__caption\"})\n",
    "    research_breakthrough_dates = research_breakthrough_name.findPrevious('p').text.strip()\n",
    "\n",
    "    spotlight_hour_table = soup.find(text = 'Pokémon Spotlight Hours').findPrevious('div', attrs = {'class':'ContainerBlock'}).find('div', attrs = {'class':\"ContainerBlock__blocks\"})\n",
    "    spotlight_hours_on_site = spotlight_hour_table.findAll('div', attrs = {'class':\"PokemonImageGridBlock__grid__pokemon__caption\"})\n",
    "    spotlight_hours_on_site = pogo_general_text_strip(spotlight_hours_on_site)\n",
    "\n",
    "    comm_day_table = soup.find(text = month + ' Community Day ').findPrevious('div', attrs = {'class':'ContainerBlock'}).find('p')\n",
    "    comm_day_info = comm_day_table.text.strip()\n",
    "    \n",
    "    upcoming_events_table = soup.find(text = 'Upcoming events').findPrevious('div', attrs = {'class':'ContainerBlock'}).find('ul')\n",
    "    upcoming_events = upcoming_events_table.text.strip()\n",
    "\n",
    "frame = get_pogo_site_info(my_soup, None, 'next')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    }
   ],
   "source": [
    "print(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "above one not verified: name, item_of_interest barb barrage barrage\n",
      "above one not verified: name, item_of_interest bubble beam bubble\n",
      "above one not verified: name, item_of_interest bug bite bite\n",
      "above one not verified: name, item_of_interest charge beam charge\n",
      "above one not verified: name, item_of_interest clangorous soulblaze clangorous soul\n",
      "above one not verified: name, item_of_interest conversion 2 conversion\n",
      "above one not verified: name, item_of_interest discharge charge\n",
      "above one not verified: name, item_of_interest head charge charge\n",
      "above one not verified: name, item_of_interest heal block block\n",
      "above one not verified: name, item_of_interest high jump kick jump kick\n",
      "above one not verified: name, item_of_interest inferno overdrive overdrive\n",
      "above one not verified: name, item_of_interest misty explosion explosion\n",
      "above one not verified: name, item_of_interest petal blizzard blizzard\n",
      "above one not verified: name, item_of_interest powder snow powder\n",
      "above one not verified: name, item_of_interest power trick trick\n",
      "above one not verified: name, item_of_interest psychic fangs psychic\n",
      "above one not verified: name, item_of_interest rage powder powder\n",
      "above one not verified: name, item_of_interest reflect type reflect\n",
      "above one not verified: name, item_of_interest sleep powder powder\n",
      "above one not verified: name, item_of_interest sludge bomb sludge\n",
      "above one not verified: name, item_of_interest sludge wave sludge\n",
      "above one not verified: name, item_of_interest splishy splash splash\n",
      "above one not verified: name, item_of_interest steam eruption eruption\n",
      "above one not verified: name, item_of_interest strength sap strength\n",
      "above one not verified: name, item_of_interest struggle bug struggle\n",
      "above one not verified: name, item_of_interest stun spore spore\n",
      "above one not verified: name, item_of_interest thunder cage thunder\n",
      "above one not verified: name, item_of_interest thunder fang thunder\n",
      "above one not verified: name, item_of_interest thunder punch thunder\n",
      "above one not verified: name, item_of_interest thunder wave thunder\n",
      "above one not verified: name, item_of_interest toxic spikes spikes\n",
      "above one not verified: name, item_of_interest trick room trick\n",
      "above one not verified: name, item_of_interest volt tackle tackle\n",
      "above one not verified: name, item_of_interest wild charge charge\n",
      "above one not verified: name, item_of_interest zen headbutt headbutt\n",
      "['barb barrage', 'bubble beam', 'bug bite', 'charge beam', 'clangorous soulblaze', 'conversion 2', 'discharge', 'head charge', 'heal block', 'high jump kick', 'inferno overdrive', 'misty explosion', 'petal blizzard', 'powder snow', 'power trick', 'psychic fangs', 'rage powder', 'reflect type', 'sleep powder', 'sludge bomb', 'sludge wave', 'splishy splash', 'steam eruption', 'strength sap', 'struggle bug', 'stun spore', 'thunder cage', 'thunder fang', 'thunder punch', 'thunder wave', 'toxic spikes', 'trick room', 'volt tackle', 'wild charge', 'zen headbutt']\n"
     ]
    }
   ],
   "source": [
    "# moves\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random \n",
    "import difflib\n",
    "import pokebot_parser\n",
    "import numpy as np \n",
    "\n",
    "def get_moves_list():\n",
    "    pokemon_data = pd.read_csv(\"pokemon_moves.csv\")\n",
    "    move_df = pd.DataFrame(pokemon_data)\n",
    "    move_names_lst = move_df['Name']\n",
    "    return move_names_lst\n",
    "\n",
    "def lower_moves_list(move_names_list):\n",
    "    for i in range(len(move_names_list)):\n",
    "        move_names_list[i] = move_names_list[i].lower()\n",
    "    return move_names_list\n",
    "    \n",
    "exceptions_lst = []\n",
    "\n",
    "def move_name_extractor(name):\n",
    "    moves_names_lst = get_moves_list()\n",
    "    moves_names_lst = lower_moves_list(moves_names_lst)\n",
    "    n = 1\n",
    "    message = name\n",
    "    game_tup = pokebot_parser.game_checker(message)\n",
    "    try:\n",
    "        message = message.replace(game_tup[1], \"\")\n",
    "    except:\n",
    "        pass \n",
    "    cutoff = 0.8\n",
    "    message = message.replace(\" \", \"\")\n",
    "    result = [message[i: j] for i in range(len(message))\n",
    "        for j in range(i + 1, len(message) + 1)]\n",
    "    substring_list = []\n",
    "    for substring in result:\n",
    "        close_matches = difflib.get_close_matches(substring, moves_names_lst, n, cutoff)\n",
    "        if (len(close_matches) > 0):\n",
    "            substring_list.append(close_matches[0])\n",
    "    unique, counts = np.unique(substring_list, return_counts=True)\n",
    "    try:\n",
    "        if (max(counts) == min(counts)):\n",
    "            item_of_interest = max(unique, key=len)\n",
    "        else:\n",
    "            item_of_interest = unique[np.argmax(counts)]\n",
    "        # print(\"final item is: \", item_of_interest)\n",
    "        if (item_of_interest != name):\n",
    "            print(\"above one not verified: name, item_of_interest\", name, item_of_interest)\n",
    "            exceptions_lst.append(name)\n",
    "    except:\n",
    "        final_extracted_item = 'Not Found ' + close_matches\n",
    "        print(final_extracted_item)\n",
    "\n",
    "\n",
    "def get_move_exceptions_lst():\n",
    "    moves_names_lst = get_moves_list()\n",
    "    moves_names_lst = lower_moves_list(moves_names_lst)\n",
    "    for i in range(len(moves_names_lst)):\n",
    "        move_name_extractor(moves_names_lst[i])\n",
    "    return exceptions_lst\n",
    "\n",
    "exc_lst = get_move_exceptions_lst()\n",
    "print(exc_lst)\n",
    "\n",
    "def exception_move_name_extractor(message, list):\n",
    "    moves_names_lst = list\n",
    "    moves_names_lst = lower_moves_list(moves_names_lst)\n",
    "    n = 1\n",
    "    # message = name\n",
    "    if (message == 'quit'):\n",
    "        print(\"QUIT\")\n",
    "    game_tup = pokebot_parser.game_checker(message)\n",
    "    try:\n",
    "        message = message.replace(game_tup[1], \"\")\n",
    "    except:\n",
    "        pass \n",
    "    cutoff = 0.95\n",
    "    message = message.replace(\" \", \"\")\n",
    "    result = [message[i: j] for i in range(len(message))\n",
    "        for j in range(i + 1, len(message) + 1)]\n",
    "    substring_list = []\n",
    "    for substring in result:\n",
    "        close_matches = difflib.get_close_matches(substring, moves_names_lst, n, cutoff)\n",
    "        if (len(close_matches) > 0):\n",
    "            substring_list.append(close_matches[0])\n",
    "    unique, counts = np.unique(substring_list, return_counts=True)\n",
    "    try:\n",
    "        if (max(counts) == min(counts)):\n",
    "            item_of_interest = max(unique, key=len)\n",
    "        else:\n",
    "            item_of_interest = unique[np.argmax(counts)]\n",
    "        # print(\"final item is: \", item_of_interest)\n",
    "    except:\n",
    "        final_extracted_item = 'Not Found'\n",
    "        # print(final_extracted_item)\n",
    "\n",
    "for i in range(len(exc_lst)):\n",
    "    exception_move_name_extractor(exc_lst[i], exc_lst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User receives recoil damage. May paralyze opponent.\n",
      "May lower opponent's Special Defense.\n",
      "High critical hit ratio.\n",
      "High critical hit ratio.\n",
      "User must recharge next turn.\n",
      "May paralyze opponent.\n",
      "User restores HP each turn. User cannot escape/switch.\n",
      "User recovers half the HP inflicted on opponent.\n",
      "User recovers half the HP inflicted on opponent.\n",
      "User recovers half the HP inflicted on opponent.\n",
      "User performs the opponent's last move.\n",
      "Ignores Accuracy and Evasiveness.\n",
      "User attacks for 2-3 turns but then becomes confused.\n",
      "Confuses opponent.\n",
      "Confuses opponent.\n",
      "User sleeps for 2 turns, but user is fully healed.\n",
      "Power increases with higher Friendship.\n",
      "Power decreases with higher Friendship.\n",
      "Pikachu-exclusive G-Max Move. Paralyzes opponents.\n",
      "User recovers half of its max HP and loses the Flying type temporarily.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'close_matches' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb Cell 4\u001b[0m in \u001b[0;36mmove_name_extractor\u001b[0;34m(name, check)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000003?line=92'>93</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000003?line=93'>94</a>\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mmax\u001b[39;49m(counts) \u001b[39m==\u001b[39m \u001b[39mmin\u001b[39m(counts)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000003?line=94'>95</a>\u001b[0m         item_of_interest \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(unique, key\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 135>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000003?line=133'>134</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000003?line=134'>135</a>\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000003?line=135'>136</a>\u001b[0m     output \u001b[39m=\u001b[39m get_move_info_csv(\u001b[39m'\u001b[39;49m\u001b[39mEffect\u001b[39;49m\u001b[39m'\u001b[39;49m, message)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000003?line=136'>137</a>\u001b[0m     \u001b[39mprint\u001b[39m(output)\n",
      "\u001b[1;32m/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb Cell 4\u001b[0m in \u001b[0;36mget_move_info_csv\u001b[0;34m(query, message)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000003?line=123'>124</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_move_info_csv\u001b[39m(query, message):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000003?line=124'>125</a>\u001b[0m     move_name \u001b[39m=\u001b[39m move_name_extractor(message, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000003?line=125'>126</a>\u001b[0m     data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mpokemon_moves.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000003?line=126'>127</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data)\n",
      "\u001b[1;32m/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb Cell 4\u001b[0m in \u001b[0;36mmove_name_extractor\u001b[0;34m(name, check)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000003?line=106'>107</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m item_of_interest\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000003?line=107'>108</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000003?line=108'>109</a>\u001b[0m     final_extracted_item \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mNot Found \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(close_matches)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#ch0000003?line=109'>110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m final_extracted_item\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'close_matches' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Final algorithm: extract a move name from a message \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random \n",
    "import difflib\n",
    "import pokebot_parser\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "def get_moves_list():\n",
    "    pokemon_data = pd.read_csv(\"pokemon_moves.csv\")\n",
    "    move_df = pd.DataFrame(pokemon_data)\n",
    "    move_names_lst = move_df['Name']\n",
    "    return move_names_lst\n",
    "\n",
    "def lower_moves_list(move_names_list):\n",
    "    for i in range(len(move_names_list)):\n",
    "        move_names_list[i] = move_names_list[i].lower()\n",
    "    return move_names_list\n",
    "\n",
    "def exceptions_move_name_extractor(result, check):\n",
    "    moves_names_lst = get_moves_list()\n",
    "    upper_moves_names_lst = get_moves_list()\n",
    "    moves_names_lst = lower_moves_list(moves_names_lst).tolist()\n",
    "\n",
    "    exceptions_lst = ['barb barrage', 'bubble beam', 'bug bite', 'charge beam', 'clangorous soulblaze', 'conversion 2', 'conversion', 'discharge', 'head charge', 'heal block', 'high jump kick', 'inferno overdrive', 'misty explosion', 'petal blizzard', 'powder snow', 'power trick',\n",
    "    'psychic fangs', 'rage powder', 'reflect type', 'sleep powder', 'sludge bomb', 'sludge wave', 'splishy splash', 'steam eruption', 'strength sap', 'struggle bug', 'stun spore', 'thunder cage', 'thunder fang', 'thunder punch', 'thunder wave', 'toxic spikes', 'trick room',\n",
    "    'volt tackle', 'wild charge', 'zen headbutt', 'gyro ball', 'heal block', 'high jump kick', 'mat block', 'sand tomb', 'stun spore', 'trick room', 'water sport', 'pyro ball', 'block', 'jump kick', 'block', 'sandstorm', 'spore', 'trick']\n",
    "\n",
    "    substring_list = []\n",
    "    n = 1\n",
    "    cutoff = 0.95\n",
    "    for substring in result:\n",
    "        close_matches = difflib.get_close_matches(substring, exceptions_lst, n, cutoff)\n",
    "        if (len(close_matches) > 0):\n",
    "            substring_list.append(close_matches[0])\n",
    "    unique, counts = np.unique(substring_list, return_counts=True)\n",
    "    try:\n",
    "        if (max(counts) == min(counts)):\n",
    "            item_of_interest = max(unique, key=len)\n",
    "            if (check == 1):\n",
    "                idx = moves_names_lst.index(item_of_interest)\n",
    "                final_extracted_item = upper_moves_names_lst[idx]\n",
    "                return final_extracted_item \n",
    "        else:\n",
    "            item_of_interest = unique[np.argmax(counts)]\n",
    "            if (check == 1):\n",
    "                idx = moves_names_lst.index(item_of_interest)\n",
    "                final_extracted_item = upper_moves_names_lst[idx]\n",
    "                return final_extracted_item \n",
    "        idx = exceptions_lst.index(item_of_interest)\n",
    "        final_extracted_item = exceptions_lst[idx]\n",
    "        return final_extracted_item\n",
    "    except:\n",
    "        final_extracted_item = 'Not Found'\n",
    "        return final_extracted_item\n",
    "\n",
    "exc_list = []\n",
    "\n",
    "def move_name_extractor(name, check):\n",
    "    moves_names_lst = get_moves_list()\n",
    "    upper_moves_names_lst = get_moves_list()\n",
    "    moves_names_lst = lower_moves_list(moves_names_lst).tolist()\n",
    "    \n",
    "    n = 1\n",
    "    message = name\n",
    "    game_tup = pokebot_parser.game_checker(message)\n",
    "    # If there's a game in the message, should probably move this into the output file \n",
    "    try:\n",
    "        message = message.replace(game_tup[1], \"\")\n",
    "    except:\n",
    "        pass \n",
    "\n",
    "    cutoff = 0.7\n",
    "    message = message.replace(\" \", \"\")\n",
    "    result = [message[i: j] for i in range(len(message))\n",
    "        for j in range(i + 1, len(message) + 1)]\n",
    "    \n",
    "    # Handle special cases for names, less able to handle spelling errors but not a huge deal\n",
    "    final_extracted_item = exceptions_move_name_extractor(result, check)\n",
    "    if (final_extracted_item != 'Not Found'):\n",
    "        return final_extracted_item\n",
    "\n",
    "    substring_list = []\n",
    "    for substring in result:\n",
    "        close_matches = difflib.get_close_matches(substring, moves_names_lst, n, cutoff)\n",
    "        if (len(close_matches) > 0):\n",
    "            substring_list.append(close_matches[0])\n",
    "    unique, counts = np.unique(substring_list, return_counts=True)\n",
    "    try:\n",
    "        if (max(counts) == min(counts)):\n",
    "            item_of_interest = max(unique, key=len)\n",
    "            if (check == 1):\n",
    "                idx = moves_names_lst.index(item_of_interest)\n",
    "                final_extracted_item = upper_moves_names_lst[idx]\n",
    "                return final_extracted_item\n",
    "            return item_of_interest\n",
    "        else:\n",
    "            item_of_interest = unique[np.argmax(counts)]\n",
    "            if (check == 1):\n",
    "                idx = moves_names_lst.index(item_of_interest)\n",
    "                final_extracted_item = upper_moves_names_lst[idx]\n",
    "                return final_extracted_item\n",
    "            return item_of_interest\n",
    "    except:\n",
    "        final_extracted_item = 'Not Found ' + str(close_matches)\n",
    "        return final_extracted_item\n",
    "\n",
    "def format_pokemondb_move_urls(move_name):\n",
    "    general_url = 'https://pokemondb.net/move/'\n",
    "    move_lst = move_name.split()\n",
    "    new_name = ''\n",
    "    for i in range(len(move_lst)):\n",
    "        move_lst[i] = move_lst[i].lower()\n",
    "    new_name = ' '.join(move_lst)\n",
    "    new_name = new_name.replace(\",\", \"\")\n",
    "    new_name = new_name.replace(\"'\", \"\")\n",
    "    new_name = new_name.replace(\" \", \"-\")\n",
    "    return general_url + new_name \n",
    "\n",
    "def get_move_info_csv(query, message):\n",
    "    move_name = move_name_extractor(message, 1)\n",
    "    data = pd.read_csv(\"pokemon_moves.csv\")\n",
    "    df = pd.DataFrame(data)\n",
    "    df.set_index('Name', inplace=True)\n",
    "    out = df.loc[move_name, query]\n",
    "    if (str(out) == 'nan'):\n",
    "        return 'No extra effects'\n",
    "    return out \n",
    "\n",
    "while True:\n",
    "    message = input()\n",
    "    output = get_move_info_csv('Effect', message)\n",
    "    print(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen link is:  https://www.serebii.net/pokedex/254.shtml\n",
      "move found is:  None\n",
      "gen link is:  https://www.serebii.net/pokedex-gs/254.shtml\n",
      "move found is:  None\n",
      "gen link is:  https://www.serebii.net/pokedex-rs/254.shtml\n",
      "move found is:  Detect\n",
      "gen link is:  https://www.serebii.net/pokedex-dp/254.shtml\n",
      "move found is:  Detect\n",
      "gen link is:  https://www.serebii.net/pokedex-bw/254.shtml\n",
      "move found is:  Detect\n",
      "gen link is:  https://www.serebii.net/pokedex-xy/254.shtml\n",
      "move found is:  Detect\n",
      "gen link is:  https://www.serebii.net/pokedex-sm/254.shtml\n",
      "move found is:  Detect\n",
      "gen link is:  https://www.serebii.net/pokedex-swsh/sceptile\n",
      "move found is:  Detect\n",
      "{'Gen 1': 'Nope', 'Gen 2': 'Nope', 'Gen 3': 'Yes it learns it in this gen', 'Gen 4': 'Yes it learns it in this gen', 'Gen 5': 'Yes it learns it in this gen', 'Gen 6': 'Yes it learns it in this gen', 'Gen 7': 'Yes it learns it in this gen', 'Gen 8': 'Yes it learns it in this gen'}\n"
     ]
    }
   ],
   "source": [
    "# might be easier than I thought\n",
    "# get url, try searching with text = 'name', if you can't find anything, then it's a no \n",
    "# otherwise it's a yes \n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep \n",
    "import random \n",
    "\n",
    "data = pd.read_csv(\"Pokemon_data.csv\")\n",
    "def get_name_from_dex_number(pokemon_id):\n",
    "    pokemon_df = pd.DataFrame(data)\n",
    "    pokemon_df.set_index(\"pokedex_number\", inplace = True)\n",
    "    pokemon_name = pokemon_df.loc[pokemon_id, 'name']\n",
    "    name_series = pd.Series(pokemon_name)\n",
    "    pokemon_name = name_series.iloc[0]\n",
    "    return pokemon_name\n",
    "\n",
    "def list_of_links_generator(pokemon_id, new_number, pokemon_page, list_of_links):\n",
    "    g1 = '/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g1)\n",
    "    g2 = '-gs/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g2)\n",
    "    g3 = '-rs/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g3)\n",
    "    g4 = '-dp/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g4)\n",
    "    g5 = '-bw/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g5)\n",
    "    g6 = '-xy/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g6)\n",
    "    g7 = '-sm/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g7)\n",
    "    g8_name = get_name_from_dex_number(pokemon_id).lower()\n",
    "    g8 = '-swsh/' + g8_name\n",
    "    list_of_links.append(pokemon_page + g8)\n",
    "\n",
    "    return list_of_links\n",
    "\n",
    "number = str(254).zfill(3)\n",
    "pokemon_page = 'https://www.serebii.net/pokedex'\n",
    "my_links = list_of_links_generator(254, number, pokemon_page, [])\n",
    "# contains links for gens 1-8 for each pokemon\n",
    "# be sure to include a try/except statement for if a link doesn't even work \n",
    "def can_learn_move(links, move_name):\n",
    "    gen_dict = {}\n",
    "    # gen 1\n",
    "    text = move_name\n",
    "    gen_num = 1\n",
    "    for i in range(len(links)):\n",
    "        gen_link = links[i]\n",
    "        print(\"gen link is: \", gen_link)\n",
    "        sleep(random.randint(0,3))\n",
    "        try:\n",
    "            page = requests.get(gen_link)\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "            move_found = soup.find(text = move_name)\n",
    "            print(\"move found is: \", move_found)\n",
    "            if len(move_found) > 0:\n",
    "                move_found = \"Yes it learns it in this gen\"\n",
    "            else:\n",
    "                move_found = \"Nope\"\n",
    "        except:\n",
    "            move_found = \"Nope\"\n",
    "        gen_dict['Gen ' + str(gen_num)] = move_found\n",
    "        gen_num += 1\n",
    "    \n",
    "    return gen_dict\n",
    "    \n",
    "test_dict = can_learn_move(my_links, \"Detect\")\n",
    "print(test_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.serebii.net/pokedex/034.shtml\n",
      "by level up in gen 1:  Can't learn by level up in gen 1\n",
      "by tm/hm in gen 1:  Can't learn by TM/HM in gen 1\n",
      "by level up in gen 2:  Can't learn by level up in gen 2\n",
      "by tm/hm in gen 2:  \n",
      "by move tutor in gen 2:  \n",
      "egg moves in gen 2:  \n"
     ]
    }
   ],
   "source": [
    "# Next one\n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep \n",
    "import random \n",
    "\n",
    "\n",
    "data = pd.read_csv(\"Pokemon_data.csv\")\n",
    "def get_name_from_dex_number(pokemon_id):\n",
    "    pokemon_df = pd.DataFrame(data)\n",
    "    pokemon_df.set_index(\"pokedex_number\", inplace = True)\n",
    "    pokemon_name = pokemon_df.loc[pokemon_id, 'name']\n",
    "    name_series = pd.Series(pokemon_name)\n",
    "    pokemon_name = name_series.iloc[0]\n",
    "    return pokemon_name\n",
    "\n",
    "def list_of_links_generator(pokemon_id, new_number, pokemon_page, list_of_links):\n",
    "    g1 = '/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g1)\n",
    "    g2 = '-gs/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g2)\n",
    "    g3 = '-rs/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g3)\n",
    "    g4 = '-dp/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g4)\n",
    "    g5 = '-bw/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g5)\n",
    "    g6 = '-xy/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g6)\n",
    "    g7 = '-sm/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g7)\n",
    "    g8_name = get_name_from_dex_number(pokemon_id).lower()\n",
    "    g8 = '-swsh/' + g8_name\n",
    "    list_of_links.append(pokemon_page + g8)\n",
    "\n",
    "    return list_of_links\n",
    "\n",
    "number = str(34).zfill(3)\n",
    "pokemon_page = 'https://www.serebii.net/pokedex'\n",
    "my_links = list_of_links_generator(34, number, pokemon_page, [])\n",
    "\n",
    "# define a function which gets a level from a table\n",
    "def get_move_level(soup, table_name, move_name):\n",
    "    move_info = soup.find(text = move_name).findPrevious('tr').find('td').text.strip()\n",
    "    return move_info \n",
    "\n",
    "def when_learn_move(links, move_name):\n",
    "    move_dict = {}\n",
    "\n",
    "    # gen 1\n",
    "    gen1_link = links[0]\n",
    "    gen1_page = requests.get(gen1_link)\n",
    "    gen1_soup = BeautifulSoup(gen1_page.content, \"html.parser\")\n",
    "    print(gen1_link)\n",
    "    try:\n",
    "        level_up = get_move_level(gen1_soup, \"Generation I Level Up\", move_name)\n",
    "    except:\n",
    "        level_up = \"Can't learn by level up in gen 1\"\n",
    "    try:\n",
    "        tm_hm = gen1_soup.find(text = 'TM & HM Attacks').findAll(text = move_name)\n",
    "        tm_hm = \"Can learn by TM!!\"\n",
    "    except:\n",
    "        tm_hm = \"Can't learn by TM/HM in gen 1\"\n",
    "    print(\"by level up in gen 1: \", level_up)\n",
    "    print(\"by tm/hm in gen 1: \", tm_hm)\n",
    "\n",
    "    sleep(random.randint(0,3))\n",
    "    # gen 2\n",
    "    gen2_link = links[1]\n",
    "    gen2_page = requests.get(gen2_link)\n",
    "    gen2_soup = BeautifulSoup(gen2_page.content, \"html.parser\")\n",
    "    try:\n",
    "        level_up = get_move_level(gen2_soup, 'Generation II Level Up', move_name)\n",
    "    except:\n",
    "        level_up = \"Can't learn by level up in gen 2\"\n",
    "    print(\"by level up in gen 2: \", level_up)\n",
    "    try:\n",
    "        tm_hm = gen2_soup.find(text = 'TM & HM Attacks').findAll(text = move_name)\n",
    "        if len(tm_hm) > 0:\n",
    "            tm_hm = \"It can learn it using a TM/HM\"\n",
    "        else:\n",
    "            tm_hm = \"\"\n",
    "    except:\n",
    "        tm_hm = \"\"\n",
    "    print(\"by tm/hm in gen 2: \", tm_hm)\n",
    "    try:\n",
    "        crystal_move_tutor = gen2_soup.find(text = 'Crystal Move Tutor Attacks').findAll(text = move_name)\n",
    "        if len(crystal_move_tutor) > 0:\n",
    "            crystal_move_tutor = \"It can learn it with the move tutor\"\n",
    "        else:\n",
    "            crystal_move_tutor = \"\"\n",
    "    except:\n",
    "        crystal_move_tutor = \"\"\n",
    "    print(\"by move tutor in gen 2: \", crystal_move_tutor)\n",
    "    try:\n",
    "        egg_moves = gen2_soup.find(text = 'Egg Moves ').findAll(text = move_name)\n",
    "        if len(egg_moves) > 0:\n",
    "            egg_moves = \"It can learn it as an egg move\"\n",
    "        else:\n",
    "            egg_moves = \"\"\n",
    "    except:\n",
    "        egg_moves = \"\"\n",
    "    print(\"egg moves in gen 2: \", egg_moves)\n",
    "\n",
    "when_learn_move(my_links, \"Frustration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TM50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# New try: just call find on a page and give out any and all info on the move\n",
    "# when does \" \" learn \" \" in \" \" \n",
    "\n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep \n",
    "import random \n",
    "\n",
    "data = pd.read_csv(\"Pokemon_data.csv\")\n",
    "def get_name_from_dex_number(pokemon_id):\n",
    "    pokemon_df = pd.DataFrame(data)\n",
    "    pokemon_df.set_index(\"pokedex_number\", inplace = True)\n",
    "    pokemon_name = pokemon_df.loc[pokemon_id, 'name']\n",
    "    name_series = pd.Series(pokemon_name)\n",
    "    pokemon_name = name_series.iloc[0]\n",
    "    return pokemon_name\n",
    "\n",
    "def list_of_links_generator(pokemon_id, new_number, pokemon_page, list_of_links):\n",
    "    g1 = '/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g1)\n",
    "    g2 = '-gs/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g2)\n",
    "    g3 = '-rs/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g3)\n",
    "    g4 = '-dp/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g4)\n",
    "    g5 = '-bw/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g5)\n",
    "    g6 = '-xy/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g6)\n",
    "    g7 = '-sm/' + new_number + '.shtml'\n",
    "    list_of_links.append(pokemon_page + g7)\n",
    "    g8_name = get_name_from_dex_number(pokemon_id).lower()\n",
    "    g8 = '-swsh/' + g8_name\n",
    "    list_of_links.append(pokemon_page + g8)\n",
    "\n",
    "    return list_of_links\n",
    "\n",
    "def gen_extractor(message):\n",
    "    idx = message.index(\"gen\")\n",
    "    return int(message[idx + 4])\n",
    "\n",
    "def get_move_information(soup, move_name):\n",
    "    # move_info = soup.findAll(text = move_name)[0].findPrevious('tr').find('td').text.strip()\n",
    "    ret_str = ''\n",
    "    move_info = soup.findAll(text = move_name)\n",
    "    for item in move_info:\n",
    "        final_item = item.findPrevious('tr').find('td').text.strip()\n",
    "        try:\n",
    "            final_item = int(final_item)\n",
    "            final_item = \"Level \" + str(final_item)\n",
    "        except:\n",
    "            pass\n",
    "        ret_str += final_item + '\\n'\n",
    "    if len(ret_str) == 0:\n",
    "        ret_str = \"It can't learn it\"\n",
    "    return ret_str \n",
    "\n",
    "def when_learn_move(links, move_name, message):\n",
    "    number = str(146).zfill(3)\n",
    "    pokemon_page = 'https://www.serebii.net/pokedex'\n",
    "    my_links = list_of_links_generator(146, number, pokemon_page, [])\n",
    "\n",
    "    idx = gen_extractor(message)\n",
    "    link = links[idx - 1]\n",
    "    page = requests.get(link)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    try:\n",
    "        move_info = get_move_information(soup, move_name)\n",
    "    except:\n",
    "        move_info = \"Error: when_learn_move\"\n",
    "    print(move_info)\n",
    "\n",
    "when_learn_move(my_links, \"Substitute\", \"When does Moltres learn sky attack in gen 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen is:  Gen 8\n",
      "Gen is:  Gen 8\n",
      "Gen is:  Gen 8\n",
      "Gen is:  Gen 3\n",
      "Gen is:  Gen 1\n",
      "no game found\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     game \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mno game found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m gen \u001b[39m=\u001b[39m get_gen_from_game(game)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGen is: \u001b[39m\u001b[39m\"\u001b[39m,gen)\n",
      "\u001b[1;32m/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb Cell 9\u001b[0m in \u001b[0;36mget_gen_from_game\u001b[0;34m(game)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_gen_from_game\u001b[39m(game):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     gen_dct \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mRed\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mBlue\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mYellow\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGold\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSilver\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCrystal\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 2\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mRuby\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSapphire\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEmerald\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFireRed\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLeafGreen\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 3\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mDiamond\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 4\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPearl\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 4\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPlatinum\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 4\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mHeartGold\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 4\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSoulSilver\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 4\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mBlack\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 5\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mWhite\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 5\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mBlack 2\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 5\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mWhite 2\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 5\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 6\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mY\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 6\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mOmega Ruby\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 6\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAlpha Sapphire\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 5\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSun\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 7\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMoon\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 7\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mUltra Sun\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 7\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mUltra Moon\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 7\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSword\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 8\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mShield\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 8\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mBrilliant Diamond\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 8\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mShining Pearl\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 8\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLegends: Arceus\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mGen 8\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tehaamadhami/Desktop/discord_chatbot/test.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m gen_dct[game]\n",
      "\u001b[0;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "# extract a game from a message: \n",
    "import pokebot_parser\n",
    "import difflib\n",
    "import numpy as np \n",
    "import move_parser\n",
    "\n",
    "def get_gen_from_game(game):\n",
    "    gen_dct = {'Red':'Gen 1', 'Blue':'Gen 1', 'Yellow':'Gen 1', 'Gold':'Gen 2', 'Silver':'Gen 2', 'Crystal':'Gen 2',\n",
    "    'Ruby':'Gen 3', 'Sapphire':'Gen 3', 'Emerald':'Gen 3', 'FireRed':'Gen 3', 'LeafGreen':'Gen 3',\n",
    "    'Diamond':'Gen 4', 'Pearl':'Gen 4', 'Platinum':'Gen 4', 'HeartGold':'Gen 4', 'SoulSilver':'Gen 4',\n",
    "    'Black':'Gen 5', 'White':'Gen 5', 'Black 2':'Gen 5', 'White 2':'Gen 5', 'X':'Gen 6', 'Y':'Gen 6', 'Omega Ruby':'Gen 6', 'Alpha Sapphire':'Gen 5',\n",
    "    'Sun':'Gen 7', 'Moon':'Gen 7', 'Ultra Sun':'Gen 7', 'Ultra Moon':'Gen 7',\n",
    "    'Sword':'Gen 8', 'Shield':'Gen 8', 'Brilliant Diamond':'Gen 8', 'Shining Pearl':'Gen 8', 'Legends: Arceus':'Gen 8'}\n",
    "    return gen_dct[game]\n",
    "\n",
    "message = ''\n",
    "\n",
    "while message != 'quit':\n",
    "    message = input(\"Enter a message: \")\n",
    "    tup = pokebot_parser.game_checker(message)\n",
    "    if tup[0] == True:\n",
    "        game = pokebot_parser.game_processor(tup)\n",
    "    else:\n",
    "        game = ''\n",
    "        print(\"no game found\")\n",
    "    gen = get_gen_from_game(game)\n",
    "    print(\"Gen is: \",gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image0': 'https://www.serebii.net//pokemongo/pokemongo.jpg', 'name0': 'Fashion Week 2022', 'dates0': 'September 27th - October 3rd 2022', 'image1': 'https://www.serebii.net//pokemongo/testyourmettle.jpg', 'name1': 'Test Your Mettle', 'dates1': 'September 16th - September 21st 2022'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep \n",
    "import random \n",
    "import io \n",
    "\n",
    "# What's the next pokemon Go event? \n",
    "\n",
    "def dct_to_string(dct):\n",
    "    ''' \n",
    "    convert a dictionary to some output string\n",
    "    '''\n",
    "    my_str = ''\n",
    "    i = 0\n",
    "    for key in dct:\n",
    "        if (i < len(dct)): \n",
    "            my_str += str(dct[key]) + '\\n'\n",
    "        else:\n",
    "            my_str += str(dct[key])\n",
    "    return my_str \n",
    "\n",
    "def pogo_events_output():\n",
    "    url = 'https://www.serebii.net/pokemongo/events.shtml'\n",
    "    serebii_url = 'https://www.serebii.net/'\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    latest_events = soup.find(attrs = {'class':'dextab'}).findAll('tr')[1:3]\n",
    "    test_dict = {}\n",
    "    final_str = 'Here are the two most recent events: \\n'\n",
    "    latest_events\n",
    "\n",
    "    i = 0\n",
    "    for item in latest_events:\n",
    "        event_details = item.findAll('td')\n",
    "        # event_details should have 3 entries, event image,name, and dates\n",
    "        try:\n",
    "            image_details = event_details[0].find('img')\n",
    "            image = serebii_url + image_details['src']\n",
    "        except:\n",
    "            image = 'No image found'\n",
    "        try:    \n",
    "            name = event_details[1].text.strip()\n",
    "        except:\n",
    "            name = \"No event name found\"\n",
    "        try:\n",
    "            dates = event_details[2].text.strip()\n",
    "        except:\n",
    "            dates = \"No dates range found\"\n",
    "        test_dict['image' + str(i)] = image \n",
    "        test_dict['name' + str(i)] = name\n",
    "        test_dict['dates' + str(i)] = dates\n",
    "        i += 1\n",
    "        # final_str += dct_to_string(test_dict)\n",
    "    return test_dict\n",
    "\n",
    "dct = pogo_events_output()\n",
    "print(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Litwick\n",
      "October 15th 2022\n"
     ]
    }
   ],
   "source": [
    "# Community Day\n",
    "# this month and next month\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import datetime\n",
    "import pandas as pd \n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pokebot_parser\n",
    "\n",
    "\n",
    "# When is the community day this month? \n",
    "# When is the community day next month? \n",
    "# When is the next community day? \n",
    "\n",
    "today = datetime.datetime.now()\n",
    "\n",
    "def has_passed(community_day):\n",
    "    # need to remove ending of day\n",
    "    community_day = community_day.split(\" \")\n",
    "    community_day[1] = ''.join(filter(str.isdigit, community_day[1]))\n",
    "\n",
    "    community_day = \" \".join(community_day)\n",
    "    community_day_object = datetime.datetime.strptime(community_day,'%B %d %Y')\n",
    "\n",
    "    return not (today <= community_day_object)\n",
    "\n",
    "def get_comm_day_info(check_next):\n",
    "    url = 'https://www.serebii.net/pokemongo/communityday.shtml'\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    current_month_year = today.strftime(\"%B %Y\")\n",
    "    comm_day_url = url = 'https://www.serebii.net/pokemongo/communityday/' + str(current_month_year.lower().replace(\" \", \"\")) +'.shtml'\n",
    "    \n",
    "    next_month_year = (today + relativedelta(months=1)).strftime('%B %Y')\n",
    "\n",
    "    current_month_comm_day = soup.find(text = current_month_year).findNext('td').text.strip()\n",
    "    name = soup.find(text = current_month_year).findNext('td').findNext('td').text.strip()\n",
    "\n",
    "    if (check_next):\n",
    "        if (has_passed(current_month_comm_day)):\n",
    "            try:\n",
    "                # it's passed and has been announced\n",
    "                next_comm_day = soup.find(text = next_month_year).findNext('td').text.strip()\n",
    "                name = soup.find(text = next_month_year).findNext('td').findNext('td').text.strip()\n",
    "                ret_str = name + '\\n' + next_comm_day\n",
    "                return ret_str \n",
    "            except:\n",
    "                # it's passed but haven't announced it yet\n",
    "                ret_str = \"I'm not sure, I can just find the one this month: \\n\" + name + '\\n' + current_month_comm_day\n",
    "                return ret_str \n",
    "        else:\n",
    "            # hasn't passed yet\n",
    "            next_comm_day = current_month_comm_day\n",
    "            ret_str = name + '\\n' + next_comm_day\n",
    "            return ret_str \n",
    "    else:\n",
    "        ret_str = name + '\\n' + current_month_comm_day\n",
    "        return ret_str  \n",
    "\n",
    "item = get_comm_day_info(check_next = True)\n",
    "print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#797 | Celesteela | Southern Hemisphere\n",
      "#798 | Kartana | Northern Hemisphere\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# raids \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random \n",
    "import difflib\n",
    "import pokebot_parser\n",
    "import numpy as np \n",
    "\n",
    "def get_star_search_string(message):\n",
    "    raids_star_lst = ['5 star', '5-star', 'five star', 'mega raids', '4-star', '4 star', 'four star', \n",
    "    '3-star', '3 star', 'three star', '2-star', '2 star', 'two star', '1-star', '1 star', 'one star']\n",
    "    # output closest match\n",
    "\n",
    "    raids_dct = {'5 star':'☆☆☆☆☆ List', '5-star':'☆☆☆☆☆ List', 'five star':'☆☆☆☆☆ List', 'mega raids':'Mega Raid List', '4-star':'☆☆☆☆ List', '4 star':'☆☆☆☆ List', 'four star':'☆☆☆☆ List', \n",
    "    '3-star':'☆☆☆ List', '3 star':'☆☆☆ List', 'three star':'☆☆☆ List', '2-star':'☆☆ List', '2 star':'☆☆ List', 'two star':'☆☆ List', '1-star':'☆ List', '1 star':'☆ List', 'one star':'☆ List'}\n",
    "    # use closest match to get search string from raids_dct\n",
    "\n",
    "    n = 1\n",
    "    cutoff = 0.9\n",
    "    message = message.replace(\" \", \"\")\n",
    "    result = [message[i: j] for i in range(len(message))\n",
    "        for j in range(i + 1, len(message) + 1)]\n",
    "\n",
    "    substring_list = []\n",
    "    for substring in result:\n",
    "        close_matches = difflib.get_close_matches(substring, raids_star_lst, n, cutoff)\n",
    "        if (len(close_matches) > 0):\n",
    "            substring_list.append(close_matches[0])\n",
    "    key = substring_list[0]\n",
    "\n",
    "    search_string = raids_dct[key]\n",
    "    return search_string\n",
    "    # use search string to get pokemon for each raid type\n",
    "\n",
    "def get_current_raid_info(message):\n",
    "    search_string = get_star_search_string(message)\n",
    "    raid_url = 'https://www.serebii.net/pokemongo/raidbattles.shtml'\n",
    "    page = requests.get(raid_url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    try:\n",
    "        table = soup.find(text = search_string).findNext('table', attrs = {'class':'dextab'}).find_all('tr')[1:]\n",
    "    except:\n",
    "        return \"I'm not sure\"\n",
    "    ret_str = ''\n",
    "    for element in table: \n",
    "        lst_num = element.findAll('td', attrs = {'class':'cen'})\n",
    "        lst_name = element.findAll('td', attrs = {'class':'fooinfo'})\n",
    "        if (len(lst_num) > 0):\n",
    "            num = lst_num[0].text.strip()\n",
    "            ret_str += num + ' | '\n",
    "        if (len(lst_name) > 0):\n",
    "            try:\n",
    "                extra_info = lst_name[0].find('i').text.strip()\n",
    "                name = lst_name[0].find('a').text.strip()\n",
    "                ret_str += name + ' | '\n",
    "                ret_str += extra_info + '\\n'\n",
    "            except:\n",
    "                name = lst_name[0].find('a').text.strip()\n",
    "                ret_str += name + '\\n' \n",
    "    return ret_str \n",
    "\n",
    "message = input(\"Ask about any current raid tiers you're curious about: \")\n",
    "item = get_current_raid_info(message)\n",
    "print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next spotlight hour is: \n",
      "September 27 2022 | Nidoran♀ | 2 * Catch Experience\n"
     ]
    }
   ],
   "source": [
    "# spotlight hour:\n",
    "#NOTE: FIX THIS SO CAN HANDLE CURRENT\n",
    "\n",
    "# what are the spotlight hours this month? \n",
    "# what's the next spotlight hour? \n",
    "\n",
    "# take today, and compare to most recent 4 days on table and see which is the first upcoming one\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import datetime\n",
    "import pandas as pd \n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "today = datetime.datetime.now()\n",
    "\n",
    "def has_passed(community_day):\n",
    "    # need to remove ending of day\n",
    "    community_day = community_day.split(\" \")\n",
    "    community_day[1] = ''.join(filter(str.isdigit, community_day[1]))\n",
    "\n",
    "    community_day = \" \".join(community_day)\n",
    "    community_day_object = datetime.datetime.strptime(community_day,'%B %d %Y')\n",
    "\n",
    "    return not (today <= community_day_object)\n",
    "\n",
    "def find_next(x, sorted_dates_lst):\n",
    "    y = [a for a in sorted_dates_lst if a > today]\n",
    "    # return y[0].strftime('%B %d %Y') if y else None\n",
    "    return y[0] if y else None\n",
    "\n",
    "def get_spotlight_hour_info(check_next):\n",
    "    url = 'https://www.serebii.net/pokemongo/events/spotlighthour.shtml'\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    table = soup.find('table', attrs = {'class':'dextab'})\n",
    "    dates = table.findAll('tr')[1:9]\n",
    "    dates_lst = []\n",
    "    dates_obj_lst = []\n",
    "    pokemon_lst = []\n",
    "    effects_lst = []\n",
    "\n",
    "    for date in dates:\n",
    "        final_date = date.findAll('td')[0].text.strip()\n",
    "        pokemon = date.findAll('td')[1].text.strip()\n",
    "        effect = date.findAll('td')[2].text.strip()\n",
    "\n",
    "        dates_lst.append(final_date)\n",
    "        pokemon_lst.append(pokemon)\n",
    "        effects_lst.append(effect)\n",
    "    \n",
    "    if (check_next == False):\n",
    "        ret_str = 'Here are some of the most recent ones I could find: \\n'\n",
    "        for i in range(len(dates_lst)):\n",
    "            date = dates_lst[i]\n",
    "            name = pokemon_lst[i]\n",
    "            effect = effects_lst[i]\n",
    "            if (i < len(dates_lst) - 1):\n",
    "                ret_str += date + \" | \" + name + \" | \" + effect + '\\n' \n",
    "            else:\n",
    "                ret_str += date + \" | \" + name + \" | \" + effect\n",
    "        return ret_str \n",
    "\n",
    "    for date in dates_lst:\n",
    "        date = date.split(\" \")\n",
    "        date[1] = ''.join(filter(str.isdigit, date[1]))\n",
    "        date = \" \".join(date)\n",
    "        date_obj = datetime.datetime.strptime(date,'%B %d %Y')\n",
    "        dates_obj_lst.append(date_obj)\n",
    "\n",
    "    # https://stackoverflow.com/questions/66165563/given-a-specific-date-find-the-next-date-in-the-list-using-python\n",
    "    dates_obj_lst.sort()\n",
    "    res = find_next(today, dates_obj_lst)\n",
    "    idx = dates_obj_lst.index(res) \n",
    "    res = res.strftime('%B %d %Y')\n",
    "    final_str = \"The next spotlight hour is: \\n\" + res + ' | ' + pokemon_lst[idx] + ' | ' + effects_lst[idx]\n",
    "\n",
    "    return final_str  \n",
    "\n",
    "item = get_spotlight_hour_info(True)\n",
    "print(item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the most recent one I could find: \n",
      "September 2022 | Medicham Encounter\n"
     ]
    }
   ],
   "source": [
    "# research breakthrough\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "\n",
    "# Searches page for most recent research breakthrough\n",
    "def get_most_recent_research_breakthroughs():\n",
    "    url = 'https://www.serebii.net/pokemongo/fieldresearch.shtml'\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    try:\n",
    "        research_breakthrough = soup.find(text = \"Field Research List\").findPrevious('p').findNext('div').find('li')\n",
    "        date = research_breakthrough.get(\"title\")\n",
    "        pokemon = research_breakthrough.find('td', attrs = {'class':'pkmn'}).findNext('td').text.strip()\n",
    "        ret_str = \"Here's the most recent one I could find: \\n\" + date + \" | \" + pokemon\n",
    "        return ret_str \n",
    "    except:\n",
    "        ret_str = \"I'm not sure!\"\n",
    "        return ret_str \n",
    "    \n",
    "item = get_most_recent_research_breakthroughs()\n",
    "print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: OLD CODE HERE\n",
    "def get_pogo_content_update_link(month_to_check):\n",
    "    ''' \n",
    "    month_to_check can be current or next month \n",
    "    '''\n",
    "    pogo_news_url = 'https://pokemongolive.com/en/news/'\n",
    "    pogo_general_url = 'https://pokemongolive.com'\n",
    "\n",
    "    news_page = requests.get(pogo_news_url)\n",
    "    news_soup = BeautifulSoup(news_page.content, \"html.parser\")\n",
    "    current_month_num = today.month \n",
    "    current_month = today.strftime(\"%B\")\n",
    "    next_month = (today + relativedelta(months=1)).strftime('%B')\n",
    "    blogpost_links = news_soup.findAll('a', attrs = {'class':'blogList__post'})\n",
    "    print(blogpost_links)\n",
    "\n",
    "    if month_to_check == 'current':\n",
    "        for item in blogpost_links:\n",
    "            if 'content-update' in item['href'] and current_month.lower() in item['href']:\n",
    "                return pogo_general_url + item['href']\n",
    "    if month_to_check == 'next':\n",
    "        for item in blogpost_links:\n",
    "            if 'content-update' in item['href'] and next_month.lower() in item['href']:\n",
    "                return pogo_general_url + item['href']\n",
    "\n",
    "# link = get_pogo_content_update_link('next')\n",
    "# print(link)\n",
    "\n",
    "def get_pogo_soup(url):\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        return soup\n",
    "    except:\n",
    "        return 'Not Found'\n",
    "\n",
    "def build_pogo_df(result, names_list, dates_list):\n",
    "    for i in range(len(names_list)):\n",
    "        row = []\n",
    "        name = names_list[i]\n",
    "        row.append(name)\n",
    "        date = dates_list[i]\n",
    "        row.append(date)\n",
    "        result.append(row)\n",
    "    return result\n",
    "\n",
    "def build_pogo_df_general(result, list):\n",
    "    for i in range(len(list)):\n",
    "        row = []\n",
    "        item = list[i]\n",
    "        row.append(item)        \n",
    "        result.append(row)\n",
    "    return result \n",
    "\n",
    "def pogo_general_text_strip(list):\n",
    "    for i in range(len(list)):\n",
    "        list[i] = list[i].text.strip()\n",
    "    return list \n",
    "\n",
    "def pogo_names_text_strip(list):\n",
    "    for i in range(len(list)):\n",
    "        list[i] = list[i].text.strip()\n",
    "        list[i] = ''.join(filter(str.isalnum, list[i]))\n",
    "    return list \n",
    "\n",
    "# my_soup = get_pogo_soup(link)\n",
    "\n",
    "def get_pogo_site_info(soup, info_to_get, timeframe):\n",
    "    res = []\n",
    "    if timeframe == 'next':\n",
    "        month = (today + relativedelta(months=1)).strftime('%B')\n",
    "    elif timeframe == 'current':\n",
    "        month = today.strftime(\"%B\")\n",
    "    \n",
    "    five_star_raid_table = soup.find(text = 'Five-Star Raids').findPrevious('div', attrs = {'class':'ContainerBlock'}).find('div', attrs = {'class':\"MarkdownBlock__blocks\"})\n",
    "    five_star_names = five_star_raid_table.findAll('div', attrs = {'class':\"PokemonImageGridBlock__grid__pokemon__caption\"})\n",
    "    five_star_names = pogo_names_text_strip(five_star_names)\n",
    "    five_star_raid_dates = soup.find(text = 'Five-Star Raids').findPrevious('div', attrs = {'class':'ContainerBlock'}).findAll('strong')\n",
    "\n",
    "    # Handle if multiple pokemon per date\n",
    "    for i in range(len(five_star_raid_dates)):\n",
    "        five_star_pokemon_on_site = five_star_raid_dates[i].findNext('div',attrs={'class':\"block block--PokemonImageGridBlock\"}).findAll('div', attrs={'class':'PokemonImageGridBlock__grid__pokemon__caption'})\n",
    "        date_duplicate_count = len(five_star_pokemon_on_site)\n",
    "        # if multiple pokemon for a date, duplicate that date entry in the list\n",
    "        if (date_duplicate_count > 1):\n",
    "            five_star_raid_dates.insert(i, five_star_raid_dates[i])\n",
    "        five_star_raid_dates[i] = five_star_raid_dates[i].text.strip()\n",
    "\n",
    "    if (info_to_get == '5-star raids'):\n",
    "        res = build_pogo_df(res, five_star_names, five_star_raid_dates)\n",
    "        df = pd.DataFrame(res, columns=[\"Name\" ,\"Dates\"])\n",
    "        df_prime = df.to_string(index = False, justify='left', header=False)\n",
    "        return df_prime\n",
    "\n",
    "    mega_raid_table = soup.find(text = 'Mega Raids').findPrevious('div', attrs = {'class':'ContainerBlock'}).find('div', attrs = {'class':\"MarkdownBlock__blocks\"})\n",
    "    mega_pokemon_on_site = mega_raid_table.findAll('div', attrs = {'class':\"PokemonImageGridBlock__grid__pokemon__caption\"})\n",
    "    mega_pokemon_on_site = pogo_names_text_strip(mega_pokemon_on_site)    \n",
    "    mega_raid_dates = soup.find(text = 'Mega Raids').findPrevious('div', attrs = {'class':'ContainerBlock'}).findAll('strong')\n",
    "    \n",
    "    # Handle if multiple pokemon per date\n",
    "    for i in range(len(mega_raid_dates)):\n",
    "        mega_pokemon_on_site = mega_raid_dates[i].findNext('div',attrs={'class':\"block block--PokemonImageGridBlock\"}).findAll('div', attrs={'class':'PokemonImageGridBlock__grid__pokemon__caption'})\n",
    "        date_duplicate_count = len(mega_pokemon_on_site)\n",
    "        # if multiple pokemon for a date, duplicate that date entry in the list\n",
    "        if (date_duplicate_count > 1):\n",
    "            mega_raid_dates.insert(i, mega_raid_dates[i])\n",
    "        mega_raid_dates[i] = mega_raid_dates[i].text.strip()\n",
    "    \n",
    "    if (info_to_get == 'mega raids'):\n",
    "        res = build_pogo_df(res, mega_pokemon_on_site, mega_raid_dates)\n",
    "        df = pd.DataFrame(res, columns=[\"Name\" ,\"Dates\"])\n",
    "        df_prime = df.to_string(index = False, justify='left', header=False)\n",
    "        return df_prime\n",
    "\n",
    "    raid_hour_table = soup.find(text = 'Raid Hours').findPrevious('div', attrs = {'class':'ContainerBlock'}).find('div', attrs = {'class':\"MarkdownBlock__blocks\"})\n",
    "    raid_hours_on_site = raid_hour_table.findAll('div', attrs = {'class':\"PokemonImageGridBlock__grid__pokemon__caption\"})\n",
    "    raid_hours_on_site = pogo_general_text_strip(raid_hours_on_site)\n",
    "\n",
    "    if (info_to_get == 'raid hour'):\n",
    "        res = build_pogo_df_general(res, raid_hours_on_site)\n",
    "        df = pd.DataFrame(res, columns=[\"Raid Hour\"])\n",
    "        df_prime = df.to_string(index = False, justify='left', header=False)\n",
    "        return df_prime\n",
    "\n",
    "    # research_breakthrough_table = soup.find(text = (now + relativedelta(months=1)).strftime('%B') + ' Research Breakthrough encounters').findPrevious('div', attrs = {'class':'ContainerBlock'}).find('div', attrs = {'class':\"MarkdownBlock__blocks\"})\n",
    "    research_breakthrough_name = soup.find(text = month + ' Research Breakthrough encounters').findPrevious('div', attrs = {'class':'ContainerBlock'}).find('div', attrs = {'class':\"PokemonImageGridBlock__grid__pokemon__caption\"})\n",
    "    research_breakthrough_dates = research_breakthrough_name.findPrevious('p').text.strip()\n",
    "    \n",
    "    if (info_to_get == 'research breakthrough'):\n",
    "        row = []\n",
    "        row.append(research_breakthrough_name)\n",
    "        row.append(research_breakthrough_dates)\n",
    "        res.append(row)\n",
    "        df = pd.DataFrame(res, columns=[\"Name\", \"Date\"])\n",
    "        df_prime = df.to_string(index = False, justify='left', header=False)\n",
    "        return df_prime\n",
    "\n",
    "    spotlight_hour_table = soup.find(text = 'Pokémon Spotlight Hours').findPrevious('div', attrs = {'class':'ContainerBlock'}).find('div', attrs = {'class':\"ContainerBlock__blocks\"})\n",
    "    spotlight_hours_on_site = spotlight_hour_table.findAll('div', attrs = {'class':\"PokemonImageGridBlock__grid__pokemon__caption\"})\n",
    "    spotlight_hours_on_site = pogo_general_text_strip(spotlight_hours_on_site)\n",
    "\n",
    "    if (info_to_get == 'spotlight hour'):\n",
    "        res = build_pogo_df_general(res, spotlight_hours_on_site)\n",
    "        df = pd.DataFrame(res, columns=[\"Spotlight Hour\"])\n",
    "        df_prime = df.to_string(index = False, justify='left', header=False)\n",
    "        return df_prime\n",
    "\n",
    "    comm_day_table = soup.find(text = month + ' Community Day ').findPrevious('div', attrs = {'class':'ContainerBlock'}).find('p')\n",
    "    comm_day_info = comm_day_table.text.strip()\n",
    "\n",
    "    if (info_to_get == 'comm day'):\n",
    "        return comm_day_info\n",
    "    \n",
    "    upcoming_events_table = soup.find(text = 'Upcoming events').findPrevious('div', attrs = {'class':'ContainerBlock'}).find('ul')\n",
    "    upcoming_events = upcoming_events_table.text.strip()\n",
    "\n",
    "    if (info_to_get == 'upcoming events'):\n",
    "        return upcoming_events\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20d66ca21a327b71db0cb3d639c2d9cfc76196a6a8c0f2b93a7dcb5ba8f54418"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
